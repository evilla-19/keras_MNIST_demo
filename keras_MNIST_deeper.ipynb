{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_MNIST_deeper.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/evilla-19/keras_MNIST_demo/blob/master/keras_MNIST_deeper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "RhxJqjOqcwUK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h6g8HCSVcybJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# set-up to upload from google drive, part 2\n",
        "import os\n",
        "!pip3 install pydrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# set-up to upload from google drive, part 3\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nYPQ2e1fcydR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# actually get the files\n",
        "!mkdir /content/inputData\n",
        "%cd /content/inputData\n",
        "download = drive.CreateFile({'id': '1TKQb-Ayc1W5aEA-sKYKPcexOwDntyDgZ'})\n",
        "download.GetContentFile('fashion-mnist_test.csv')\n",
        "download = drive.CreateFile({'id': '13Pye-aQ9chnOTo_dBWGha9zG2IuZq_yQ'})\n",
        "download.GetContentFile('fashion-mnist_train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5NuLAOZjcyfp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# split the training and testing data into X (image) and Y (label) arrays\n",
        "\n",
        "train_df = pd.read_csv(r'fashion-mnist_train.csv')\n",
        "test_df = pd.read_csv(r'fashion-mnist_test.csv')\n",
        "\n",
        "train_data = np.array(train_df, dtype='float32')\n",
        "test_data = np.array(test_df, dtype='float32')\n",
        "\n",
        "x_train = train_data[:, 1:] / 255\n",
        "y_train = train_data[:, 0]\n",
        "\n",
        "x_test = test_data[:, 1:] / 255\n",
        "y_test = test_data[:, 0]\n",
        "\n",
        "x_train, x_validate, y_train, y_validate = train_test_split(\n",
        "    x_train, y_train, test_size=0.2, random_state=12345,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lF4evts1KlIA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# lets see what the images look like\n",
        "\n",
        "image = x_train[50, :].reshape((28, 28))\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wW141ghbcyh5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reshape the data\n",
        "\n",
        "im_rows = 28\n",
        "im_cols = 28\n",
        "batch_size = 512\n",
        "im_shape = (im_rows, im_cols, 1)\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], *im_shape)\n",
        "x_test = x_test.reshape(x_test.shape[0], *im_shape)\n",
        "x_validate = x_validate.reshape(x_validate.shape[0], *im_shape)\n",
        "\n",
        "\n",
        "print('X train shape is: {}'.format(x_train.shape))\n",
        "print('Y train shape is: {}'.format(y_train.shape))\n",
        "\n",
        "print('A peek into X train: {}'.format(x_train[0]))\n",
        "print('A peek into Y train: {}'.format(y_train[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yrBDyzQ3M4l1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !pip install tensorboardcolab\n",
        "from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback\n",
        "\n",
        "tbc=TensorBoardColab()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tau4LtEBOK0g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "\n",
        "cnn_model = Sequential([\n",
        "    Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=im_shape),\n",
        "    MaxPooling2D(pool_size=2),\n",
        "    Dropout(0.2),\n",
        "    \n",
        "    Flatten(),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "cnn_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tRIFww5AOWiw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Compile and fit the model\n",
        "\n",
        "cnn_model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=Adam(lr=0.001),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "cnn_model.fit(\n",
        "    x_train, y_train, batch_size=batch_size,\n",
        "    epochs=30, verbose=1,\n",
        "    validation_data=(x_validate, y_validate),\n",
        "    callbacks=[TensorBoardColabCallback(tbc)]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "doteOUP9OaTx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "score = cnn_model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "print('test loss: {:.4f}'.format(score[0]))\n",
        "print(' test acc: {:.4f}'.format(score[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bEBc9Jf1cykT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# our 3 models \n",
        "\n",
        "name = '1_Layer'\n",
        "cnn_model_1 = Sequential([\n",
        "    Conv2D(32, kernel_size=3, activation='relu', input_shape=im_shape, name='Conv2D-1'),\n",
        "    MaxPooling2D(pool_size=2, name='MaxPool'),\n",
        "    Dropout(0.2, name='Dropout'),\n",
        "    Flatten(name='flatten'),\n",
        "    Dense(32, activation='relu', name='Dense'),\n",
        "    Dense(10, activation='softmax', name='Output')\n",
        "], name=name)\n",
        "\n",
        "name = '2_Layer'\n",
        "cnn_model_2 = Sequential([\n",
        "    Conv2D(32, kernel_size=3, activation='relu', input_shape=im_shape, name='Conv2D-1'),\n",
        "    MaxPooling2D(pool_size=2, name='MaxPool'),\n",
        "    Dropout(0.2, name='Dropout-1'),\n",
        "    Conv2D(64, kernel_size=3, activation='relu', name='Conv2D-2'),\n",
        "    Dropout(0.25, name='Dropout-2'),\n",
        "    Flatten(name='flatten'),\n",
        "    Dense(64, activation='relu', name='Dense'),\n",
        "    Dense(10, activation='softmax', name='Output')\n",
        "], name=name)\n",
        "\n",
        "name='3_layer'\n",
        "cnn_model_3 = Sequential([\n",
        "    Conv2D(32, kernel_size=3, activation='relu', \n",
        "           input_shape=im_shape, kernel_initializer='he_normal', name='Conv2D-1'),\n",
        "    MaxPooling2D(pool_size=2, name='MaxPool'),\n",
        "    Dropout(0.25, name='Dropout-1'),\n",
        "    Conv2D(64, kernel_size=3, activation='relu', name='Conv2D-2'),\n",
        "    Dropout(0.25, name='Dropout-2'),\n",
        "    Conv2D(128, kernel_size=3, activation='relu', name='Conv2D-3'),\n",
        "    Dropout(0.4, name='Dropout-3'),\n",
        "    Flatten(name='flatten'),\n",
        "    Dense(128, activation='relu', name='Dense'),\n",
        "    Dropout(0.4, name='Dropout'),\n",
        "    Dense(10, activation='softmax', name='Output')\n",
        "], name=name)\n",
        "\n",
        "cnn_models = [cnn_model_1, cnn_model_2, cnn_model_3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c-mE4gbccymZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# the model summaries\n",
        "\n",
        "for model in cnn_models:\n",
        "    model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZpEECirkcyos",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train the models and save results to a dict\n",
        "\n",
        "history_dict = {}\n",
        "\n",
        "for model in cnn_models:\n",
        "    model.compile(\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        optimizer=Adam(),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    history = model.fit(\n",
        "        x_train, y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=50, verbose=1,\n",
        "        validation_data=(x_validate, y_validate),\n",
        "        callbacks = [TensorBoardColabCallback(tbc)]\n",
        "    )\n",
        "    \n",
        "    history_dict[model.name] = history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xr5sXY53cyq4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for model in cnn_models:\n",
        "  score = model.evaluate(x_test, y_test, verbose=0)\n",
        "  print('Test loss of {} is : {}'.format(model.name, score[0]))\n",
        "  print('Test accuracy of {} is : {}'.format(model.name, score[1]))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}