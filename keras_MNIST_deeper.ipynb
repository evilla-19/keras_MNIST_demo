{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_MNIST_deeper.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/evilla-19/keras_MNIST_demo/blob/master/keras_MNIST_deeper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "8FpyBuB6yAY9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Following https://www.youtube.com/watch?v=lOZGYzTn9Z8"
      ]
    },
    {
      "metadata": {
        "id": "RhxJqjOqcwUK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h6g8HCSVcybJ",
        "colab_type": "code",
        "outputId": "b0260ee3-2530-4c65-c20d-014f16ab0c10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "cell_type": "code",
      "source": [
        "# set-up to upload from google drive, part 2\n",
        "import os\n",
        "!pip3 install pydrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# set-up to upload from google drive, part 3\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (3.13)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from pydrive) (1.6.7)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (4.1.3)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (1.11.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (3.0.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (0.11.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.2.4)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.4.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nYPQ2e1fcydR",
        "colab_type": "code",
        "outputId": "8d7c7787-4ebd-4aff-bc9b-cd73221f3c48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "# actually get the files\n",
        "!mkdir /content/inputData\n",
        "%cd /content/inputData\n",
        "download = drive.CreateFile({'id': '1TKQb-Ayc1W5aEA-sKYKPcexOwDntyDgZ'})\n",
        "download.GetContentFile('fashion-mnist_test.csv')\n",
        "download = drive.CreateFile({'id': '13Pye-aQ9chnOTo_dBWGha9zG2IuZq_yQ'})\n",
        "download.GetContentFile('fashion-mnist_train.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/content/inputData’: File exists\n",
            "/content/inputData\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5NuLAOZjcyfp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# split the training and testing data into X (image) and Y (label) arrays\n",
        "\n",
        "train_df = pd.read_csv(r'fashion-mnist_train.csv')\n",
        "test_df = pd.read_csv(r'fashion-mnist_test.csv')\n",
        "\n",
        "train_data = np.array(train_df, dtype='float32')\n",
        "test_data = np.array(test_df, dtype='float32')\n",
        "\n",
        "x_train = train_data[:, 1:] / 255\n",
        "y_train = train_data[:, 0]\n",
        "\n",
        "x_test = test_data[:, 1:] / 255\n",
        "y_test = test_data[:, 0]\n",
        "\n",
        "x_train, x_validate, y_train, y_validate = train_test_split(\n",
        "    x_train, y_train, test_size=0.2, random_state=12345,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lF4evts1KlIA",
        "colab_type": "code",
        "outputId": "7c73d7e5-e52a-46e5-e59e-add676e5e40f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "# lets see what the images look like\n",
        "\n",
        "image = x_train[53, :].reshape((28, 28))\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.show()\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAj+D3mA3EzKsTYtAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "wW141ghbcyh5",
        "colab_type": "code",
        "outputId": "59bc3544-29d8-46bb-c20f-6c92ad73e635",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 14127
        }
      },
      "cell_type": "code",
      "source": [
        "# reshape the data\n",
        "\n",
        "im_rows = 28\n",
        "im_cols = 28\n",
        "batch_size = 512\n",
        "im_shape = (im_rows, im_cols, 1)\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], *im_shape)\n",
        "x_test = x_test.reshape(x_test.shape[0], *im_shape)\n",
        "x_validate = x_validate.reshape(x_validate.shape[0], *im_shape)\n",
        "\n",
        "\n",
        "print('X train shape is: {}'.format(x_train.shape))\n",
        "print('Y train shape is: {}'.format(y_train.shape))\n",
        "\n",
        "print('A peek into X train: {}'.format(x_train[0]))\n",
        "print('A peek into Y train: {}'.format(y_train[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X train shape is: (48000, 28, 28, 1)\n",
            "Y train shape is: (48000,)\n",
            "A peek into X train: [[[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.00392157]\n",
            "  [0.00392157]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.5764706 ]\n",
            "  [0.18039216]\n",
            "  [0.49019608]\n",
            "  [0.5647059 ]\n",
            "  [0.42745098]\n",
            "  [0.33333334]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.00392157]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.10196079]\n",
            "  [0.21568628]\n",
            "  [0.8862745 ]\n",
            "  [0.8       ]\n",
            "  [0.63529414]\n",
            "  [0.6431373 ]\n",
            "  [0.827451  ]\n",
            "  [0.972549  ]\n",
            "  [0.03921569]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.00392157]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.11764706]\n",
            "  [0.28235295]\n",
            "  [0.32156864]\n",
            "  [0.38431373]\n",
            "  [0.24313726]\n",
            "  [0.22745098]\n",
            "  [0.54901963]\n",
            "  [0.63529414]\n",
            "  [0.6117647 ]\n",
            "  [0.45882353]\n",
            "  [0.14117648]\n",
            "  [0.3137255 ]\n",
            "  [0.3019608 ]\n",
            "  [0.29411766]\n",
            "  [0.14117648]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.00392157]\n",
            "  [0.        ]\n",
            "  [0.01176471]\n",
            "  [0.43137255]\n",
            "  [0.34509805]\n",
            "  [0.1764706 ]\n",
            "  [0.21568628]\n",
            "  [0.23529412]\n",
            "  [0.28235295]\n",
            "  [0.09803922]\n",
            "  [0.1882353 ]\n",
            "  [0.13725491]\n",
            "  [0.15686275]\n",
            "  [0.23529412]\n",
            "  [0.24705882]\n",
            "  [0.21568628]\n",
            "  [0.21568628]\n",
            "  [0.41960785]\n",
            "  [0.34509805]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.26666668]\n",
            "  [0.1764706 ]\n",
            "  [0.32156864]\n",
            "  [0.1882353 ]\n",
            "  [0.2627451 ]\n",
            "  [0.28627452]\n",
            "  [0.28235295]\n",
            "  [0.20784314]\n",
            "  [0.3529412 ]\n",
            "  [0.22352941]\n",
            "  [0.25490198]\n",
            "  [0.22352941]\n",
            "  [0.22745098]\n",
            "  [0.22352941]\n",
            "  [0.1764706 ]\n",
            "  [0.24313726]\n",
            "  [0.29411766]\n",
            "  [0.1882353 ]\n",
            "  [0.        ]\n",
            "  [0.00392157]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.01176471]\n",
            "  [0.3019608 ]\n",
            "  [0.09803922]\n",
            "  [0.34509805]\n",
            "  [0.28627452]\n",
            "  [0.34117648]\n",
            "  [0.32156864]\n",
            "  [0.20392157]\n",
            "  [0.21568628]\n",
            "  [0.3529412 ]\n",
            "  [0.22745098]\n",
            "  [0.20784314]\n",
            "  [0.25490198]\n",
            "  [0.30588236]\n",
            "  [0.20784314]\n",
            "  [0.22352941]\n",
            "  [0.2627451 ]\n",
            "  [0.22745098]\n",
            "  [0.26666668]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.10196079]\n",
            "  [0.22745098]\n",
            "  [0.20784314]\n",
            "  [0.39215687]\n",
            "  [0.3019608 ]\n",
            "  [0.28235295]\n",
            "  [0.25490198]\n",
            "  [0.24705882]\n",
            "  [0.18039216]\n",
            "  [0.3137255 ]\n",
            "  [0.29411766]\n",
            "  [0.22745098]\n",
            "  [0.21568628]\n",
            "  [0.20784314]\n",
            "  [0.19607843]\n",
            "  [0.30588236]\n",
            "  [0.4117647 ]\n",
            "  [0.14901961]\n",
            "  [0.29411766]\n",
            "  [0.08235294]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.14117648]\n",
            "  [0.24705882]\n",
            "  [0.20784314]\n",
            "  [0.59607846]\n",
            "  [0.28627452]\n",
            "  [0.25490198]\n",
            "  [0.24313726]\n",
            "  [0.24705882]\n",
            "  [0.1764706 ]\n",
            "  [0.25490198]\n",
            "  [0.3019608 ]\n",
            "  [0.22352941]\n",
            "  [0.1764706 ]\n",
            "  [0.16078432]\n",
            "  [0.20392157]\n",
            "  [0.3019608 ]\n",
            "  [0.44705883]\n",
            "  [0.09803922]\n",
            "  [0.23529412]\n",
            "  [0.14901961]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.21568628]\n",
            "  [0.1882353 ]\n",
            "  [0.2627451 ]\n",
            "  [0.654902  ]\n",
            "  [0.26666668]\n",
            "  [0.3019608 ]\n",
            "  [0.26666668]\n",
            "  [0.20784314]\n",
            "  [0.23529412]\n",
            "  [0.3019608 ]\n",
            "  [0.3137255 ]\n",
            "  [0.24313726]\n",
            "  [0.22352941]\n",
            "  [0.16862746]\n",
            "  [0.18039216]\n",
            "  [0.3254902 ]\n",
            "  [0.4392157 ]\n",
            "  [0.19607843]\n",
            "  [0.16862746]\n",
            "  [0.13725491]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.28235295]\n",
            "  [0.23529412]\n",
            "  [0.38039216]\n",
            "  [0.5568628 ]\n",
            "  [0.32156864]\n",
            "  [0.28627452]\n",
            "  [0.26666668]\n",
            "  [0.20784314]\n",
            "  [0.18039216]\n",
            "  [0.40784314]\n",
            "  [0.38039216]\n",
            "  [0.22352941]\n",
            "  [0.20784314]\n",
            "  [0.20784314]\n",
            "  [0.23529412]\n",
            "  [0.36078432]\n",
            "  [0.49803922]\n",
            "  [0.24313726]\n",
            "  [0.1764706 ]\n",
            "  [0.20784314]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.25490198]\n",
            "  [0.25490198]\n",
            "  [0.4117647 ]\n",
            "  [0.5372549 ]\n",
            "  [0.27450982]\n",
            "  [0.3529412 ]\n",
            "  [0.27450982]\n",
            "  [0.23529412]\n",
            "  [0.14901961]\n",
            "  [0.4509804 ]\n",
            "  [0.33333334]\n",
            "  [0.22745098]\n",
            "  [0.19607843]\n",
            "  [0.24705882]\n",
            "  [0.20784314]\n",
            "  [0.32156864]\n",
            "  [0.62352943]\n",
            "  [0.22352941]\n",
            "  [0.20392157]\n",
            "  [0.32156864]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.3254902 ]\n",
            "  [0.22352941]\n",
            "  [0.44705883]\n",
            "  [0.6627451 ]\n",
            "  [0.21568628]\n",
            "  [0.3254902 ]\n",
            "  [0.26666668]\n",
            "  [0.22745098]\n",
            "  [0.15686275]\n",
            "  [0.5176471 ]\n",
            "  [0.3254902 ]\n",
            "  [0.1764706 ]\n",
            "  [0.21568628]\n",
            "  [0.22745098]\n",
            "  [0.22745098]\n",
            "  [0.28627452]\n",
            "  [0.59607846]\n",
            "  [0.32156864]\n",
            "  [0.1882353 ]\n",
            "  [0.30588236]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.03921569]\n",
            "  [0.26666668]\n",
            "  [0.23529412]\n",
            "  [0.5647059 ]\n",
            "  [0.7137255 ]\n",
            "  [0.18039216]\n",
            "  [0.38431373]\n",
            "  [0.3137255 ]\n",
            "  [0.22352941]\n",
            "  [0.11764706]\n",
            "  [0.5254902 ]\n",
            "  [0.42745098]\n",
            "  [0.1882353 ]\n",
            "  [0.22352941]\n",
            "  [0.20392157]\n",
            "  [0.24705882]\n",
            "  [0.22352941]\n",
            "  [0.38431373]\n",
            "  [0.45882353]\n",
            "  [0.16078432]\n",
            "  [0.3019608 ]\n",
            "  [0.04313726]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.09803922]\n",
            "  [0.21568628]\n",
            "  [0.24705882]\n",
            "  [0.58431375]\n",
            "  [0.42745098]\n",
            "  [0.30588236]\n",
            "  [0.39215687]\n",
            "  [0.3137255 ]\n",
            "  [0.23529412]\n",
            "  [0.1882353 ]\n",
            "  [0.6039216 ]\n",
            "  [0.43137255]\n",
            "  [0.20392157]\n",
            "  [0.22745098]\n",
            "  [0.23529412]\n",
            "  [0.28627452]\n",
            "  [0.3019608 ]\n",
            "  [0.25490198]\n",
            "  [0.5647059 ]\n",
            "  [0.23529412]\n",
            "  [0.25490198]\n",
            "  [0.10196079]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.07058824]\n",
            "  [0.3019608 ]\n",
            "  [0.4       ]\n",
            "  [0.7137255 ]\n",
            "  [0.16078432]\n",
            "  [0.40784314]\n",
            "  [0.30588236]\n",
            "  [0.26666668]\n",
            "  [0.22352941]\n",
            "  [0.19607843]\n",
            "  [0.6431373 ]\n",
            "  [0.3529412 ]\n",
            "  [0.18039216]\n",
            "  [0.22352941]\n",
            "  [0.29411766]\n",
            "  [0.26666668]\n",
            "  [0.29411766]\n",
            "  [0.13725491]\n",
            "  [0.5882353 ]\n",
            "  [0.3529412 ]\n",
            "  [0.32156864]\n",
            "  [0.09803922]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.14901961]\n",
            "  [0.3137255 ]\n",
            "  [0.50980395]\n",
            "  [0.69411767]\n",
            "  [0.07058824]\n",
            "  [0.4       ]\n",
            "  [0.34509805]\n",
            "  [0.28627452]\n",
            "  [0.20784314]\n",
            "  [0.21568628]\n",
            "  [0.5647059 ]\n",
            "  [0.40784314]\n",
            "  [0.20392157]\n",
            "  [0.20784314]\n",
            "  [0.26666668]\n",
            "  [0.2627451 ]\n",
            "  [0.33333334]\n",
            "  [0.05098039]\n",
            "  [0.5294118 ]\n",
            "  [0.3647059 ]\n",
            "  [0.29411766]\n",
            "  [0.10196079]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.25490198]\n",
            "  [0.30588236]\n",
            "  [0.54901963]\n",
            "  [0.6117647 ]\n",
            "  [0.        ]\n",
            "  [0.44705883]\n",
            "  [0.34509805]\n",
            "  [0.3019608 ]\n",
            "  [0.24313726]\n",
            "  [0.1882353 ]\n",
            "  [0.63529414]\n",
            "  [0.43137255]\n",
            "  [0.20392157]\n",
            "  [0.24705882]\n",
            "  [0.2627451 ]\n",
            "  [0.26666668]\n",
            "  [0.33333334]\n",
            "  [0.09019608]\n",
            "  [0.47058824]\n",
            "  [0.42745098]\n",
            "  [0.3019608 ]\n",
            "  [0.12156863]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.26666668]\n",
            "  [0.28235295]\n",
            "  [0.58431375]\n",
            "  [0.5254902 ]\n",
            "  [0.01176471]\n",
            "  [0.42745098]\n",
            "  [0.30588236]\n",
            "  [0.33333334]\n",
            "  [0.19607843]\n",
            "  [0.1882353 ]\n",
            "  [0.6117647 ]\n",
            "  [0.43137255]\n",
            "  [0.21568628]\n",
            "  [0.22745098]\n",
            "  [0.20392157]\n",
            "  [0.28235295]\n",
            "  [0.36078432]\n",
            "  [0.12156863]\n",
            "  [0.4392157 ]\n",
            "  [0.4862745 ]\n",
            "  [0.27450982]\n",
            "  [0.1764706 ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.28235295]\n",
            "  [0.24313726]\n",
            "  [0.59607846]\n",
            "  [0.47058824]\n",
            "  [0.10980392]\n",
            "  [0.4       ]\n",
            "  [0.29411766]\n",
            "  [0.3137255 ]\n",
            "  [0.20392157]\n",
            "  [0.19607843]\n",
            "  [0.6039216 ]\n",
            "  [0.39215687]\n",
            "  [0.24313726]\n",
            "  [0.22352941]\n",
            "  [0.23529412]\n",
            "  [0.26666668]\n",
            "  [0.33333334]\n",
            "  [0.0627451 ]\n",
            "  [0.49803922]\n",
            "  [0.49803922]\n",
            "  [0.2627451 ]\n",
            "  [0.20392157]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.22745098]\n",
            "  [0.25490198]\n",
            "  [0.7529412 ]\n",
            "  [0.3529412 ]\n",
            "  [0.14117648]\n",
            "  [0.34117648]\n",
            "  [0.3019608 ]\n",
            "  [0.3137255 ]\n",
            "  [0.22745098]\n",
            "  [0.16862746]\n",
            "  [0.59607846]\n",
            "  [0.40784314]\n",
            "  [0.24705882]\n",
            "  [0.25490198]\n",
            "  [0.22352941]\n",
            "  [0.25490198]\n",
            "  [0.3019608 ]\n",
            "  [0.10196079]\n",
            "  [0.47058824]\n",
            "  [0.59607846]\n",
            "  [0.25490198]\n",
            "  [0.18039216]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.28627452]\n",
            "  [0.26666668]\n",
            "  [0.78039217]\n",
            "  [0.24705882]\n",
            "  [0.19607843]\n",
            "  [0.40784314]\n",
            "  [0.38039216]\n",
            "  [0.24705882]\n",
            "  [0.24705882]\n",
            "  [0.1882353 ]\n",
            "  [0.68235296]\n",
            "  [0.45882353]\n",
            "  [0.23529412]\n",
            "  [0.22352941]\n",
            "  [0.20784314]\n",
            "  [0.3137255 ]\n",
            "  [0.28627452]\n",
            "  [0.10980392]\n",
            "  [0.32156864]\n",
            "  [0.67058825]\n",
            "  [0.20392157]\n",
            "  [0.24705882]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.29411766]\n",
            "  [0.24313726]\n",
            "  [0.7411765 ]\n",
            "  [0.27450982]\n",
            "  [0.30588236]\n",
            "  [0.36078432]\n",
            "  [0.38431373]\n",
            "  [0.34509805]\n",
            "  [0.26666668]\n",
            "  [0.21568628]\n",
            "  [0.6509804 ]\n",
            "  [0.54509807]\n",
            "  [0.25490198]\n",
            "  [0.2627451 ]\n",
            "  [0.21568628]\n",
            "  [0.36078432]\n",
            "  [0.27450982]\n",
            "  [0.14901961]\n",
            "  [0.26666668]\n",
            "  [0.7490196 ]\n",
            "  [0.24705882]\n",
            "  [0.25490198]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.22745098]\n",
            "  [0.22352941]\n",
            "  [0.7490196 ]\n",
            "  [0.28235295]\n",
            "  [0.36078432]\n",
            "  [0.25490198]\n",
            "  [0.37254903]\n",
            "  [0.34117648]\n",
            "  [0.26666668]\n",
            "  [0.16078432]\n",
            "  [0.54901963]\n",
            "  [0.58431375]\n",
            "  [0.26666668]\n",
            "  [0.28235295]\n",
            "  [0.20784314]\n",
            "  [0.28235295]\n",
            "  [0.3647059 ]\n",
            "  [0.21568628]\n",
            "  [0.25490198]\n",
            "  [0.73333335]\n",
            "  [0.16078432]\n",
            "  [0.27450982]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.24705882]\n",
            "  [0.28627452]\n",
            "  [0.85882354]\n",
            "  [0.22352941]\n",
            "  [0.38039216]\n",
            "  [0.24705882]\n",
            "  [0.37254903]\n",
            "  [0.3254902 ]\n",
            "  [0.27450982]\n",
            "  [0.10196079]\n",
            "  [0.6039216 ]\n",
            "  [0.5254902 ]\n",
            "  [0.2627451 ]\n",
            "  [0.24705882]\n",
            "  [0.1882353 ]\n",
            "  [0.28627452]\n",
            "  [0.32156864]\n",
            "  [0.25490198]\n",
            "  [0.14901961]\n",
            "  [0.73333335]\n",
            "  [0.16078432]\n",
            "  [0.23529412]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.15686275]\n",
            "  [0.27450982]\n",
            "  [0.7882353 ]\n",
            "  [0.07058824]\n",
            "  [0.33333334]\n",
            "  [0.30588236]\n",
            "  [0.4       ]\n",
            "  [0.3529412 ]\n",
            "  [0.4117647 ]\n",
            "  [0.27450982]\n",
            "  [0.54901963]\n",
            "  [0.5647059 ]\n",
            "  [0.36078432]\n",
            "  [0.33333334]\n",
            "  [0.24705882]\n",
            "  [0.25490198]\n",
            "  [0.26666668]\n",
            "  [0.30588236]\n",
            "  [0.14901961]\n",
            "  [0.76862746]\n",
            "  [0.28627452]\n",
            "  [0.21568628]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.26666668]\n",
            "  [0.54509807]\n",
            "  [0.67058825]\n",
            "  [0.        ]\n",
            "  [0.49803922]\n",
            "  [0.42745098]\n",
            "  [0.4509804 ]\n",
            "  [0.41960785]\n",
            "  [0.3529412 ]\n",
            "  [0.3647059 ]\n",
            "  [0.4392157 ]\n",
            "  [0.46666667]\n",
            "  [0.45882353]\n",
            "  [0.38039216]\n",
            "  [0.44705883]\n",
            "  [0.46666667]\n",
            "  [0.46666667]\n",
            "  [0.32156864]\n",
            "  [0.        ]\n",
            "  [0.5882353 ]\n",
            "  [0.09019608]\n",
            "  [0.10980392]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.80784315]\n",
            "  [1.        ]\n",
            "  [0.972549  ]\n",
            "  [0.        ]\n",
            "  [0.20392157]\n",
            "  [0.23529412]\n",
            "  [0.22745098]\n",
            "  [0.3019608 ]\n",
            "  [0.27450982]\n",
            "  [0.27450982]\n",
            "  [0.23529412]\n",
            "  [0.22352941]\n",
            "  [0.34117648]\n",
            "  [0.32156864]\n",
            "  [0.3254902 ]\n",
            "  [0.27450982]\n",
            "  [0.22745098]\n",
            "  [0.04313726]\n",
            "  [0.        ]\n",
            "  [0.95686275]\n",
            "  [0.84705883]\n",
            "  [0.827451  ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.10196079]\n",
            "  [0.12156863]\n",
            "  [0.16078432]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.68235296]\n",
            "  [0.70980394]\n",
            "  [0.54509807]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]]\n",
            "A peek into Y train: 6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yrBDyzQ3M4l1",
        "colab_type": "code",
        "outputId": "b9510be2-cf07-4445-97c6-f274ad9126fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# !pip install tensorboardcolab\n",
        "from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback\n",
        "\n",
        "tbc=TensorBoardColab()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "http://6125f185.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tau4LtEBOK0g",
        "colab_type": "code",
        "outputId": "4a4aa241-a437-4123-c6a1-dd44f92253bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "\n",
        "cnn_model = Sequential([\n",
        "    Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=im_shape),\n",
        "    MaxPooling2D(pool_size=2),\n",
        "    Dropout(0.2),\n",
        "    \n",
        "    Flatten(),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "cnn_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 5408)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 32)                173088    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 173,738\n",
            "Trainable params: 173,738\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x4_Cm-I6aUfa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# print(cnn_model.layers)\n",
        "\n",
        "from keras.utils import plot_model\n",
        "plot_model(cnn_model, to_file='cnn_model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tRIFww5AOWiw",
        "colab_type": "code",
        "outputId": "391da7bf-6345-450c-fa29-4da95dfc1861",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1100
        }
      },
      "cell_type": "code",
      "source": [
        "# Compile and fit the model\n",
        "\n",
        "cnn_model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=Adam(lr=0.001),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "cnn_model.fit(\n",
        "    x_train, y_train, batch_size=batch_size,\n",
        "    epochs=30, verbose=1,\n",
        "    validation_data=(x_validate, y_validate),\n",
        "    callbacks=[TensorBoardColabCallback(tbc)]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/30\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.7682 - acc: 0.7514 - val_loss: 0.4545 - val_acc: 0.8443\n",
            "Epoch 2/30\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.4225 - acc: 0.8520 - val_loss: 0.3833 - val_acc: 0.8652\n",
            "Epoch 3/30\n",
            "48000/48000 [==============================] - 2s 32us/step - loss: 0.3745 - acc: 0.8695 - val_loss: 0.3455 - val_acc: 0.8792\n",
            "Epoch 4/30\n",
            "48000/48000 [==============================] - 2s 32us/step - loss: 0.3447 - acc: 0.8786 - val_loss: 0.3275 - val_acc: 0.8866\n",
            "Epoch 5/30\n",
            "48000/48000 [==============================] - 2s 32us/step - loss: 0.3237 - acc: 0.8870 - val_loss: 0.3185 - val_acc: 0.8866\n",
            "Epoch 6/30\n",
            "48000/48000 [==============================] - 2s 32us/step - loss: 0.3118 - acc: 0.8906 - val_loss: 0.3021 - val_acc: 0.8928\n",
            "Epoch 7/30\n",
            "48000/48000 [==============================] - 2s 32us/step - loss: 0.3001 - acc: 0.8945 - val_loss: 0.2938 - val_acc: 0.8977\n",
            "Epoch 8/30\n",
            "48000/48000 [==============================] - 2s 32us/step - loss: 0.2915 - acc: 0.8957 - val_loss: 0.3069 - val_acc: 0.8883\n",
            "Epoch 9/30\n",
            "48000/48000 [==============================] - 2s 32us/step - loss: 0.2827 - acc: 0.9004 - val_loss: 0.2819 - val_acc: 0.8989\n",
            "Epoch 10/30\n",
            "48000/48000 [==============================] - 2s 32us/step - loss: 0.2712 - acc: 0.9050 - val_loss: 0.2830 - val_acc: 0.8982\n",
            "Epoch 11/30\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.2689 - acc: 0.9051 - val_loss: 0.2737 - val_acc: 0.9014\n",
            "Epoch 12/30\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.2599 - acc: 0.9073 - val_loss: 0.2679 - val_acc: 0.9036\n",
            "Epoch 13/30\n",
            "48000/48000 [==============================] - 2s 32us/step - loss: 0.2545 - acc: 0.9095 - val_loss: 0.2844 - val_acc: 0.8977\n",
            "Epoch 14/30\n",
            "48000/48000 [==============================] - 2s 32us/step - loss: 0.2494 - acc: 0.9103 - val_loss: 0.2645 - val_acc: 0.9039\n",
            "Epoch 15/30\n",
            "48000/48000 [==============================] - 2s 32us/step - loss: 0.2440 - acc: 0.9126 - val_loss: 0.2639 - val_acc: 0.9042\n",
            "Epoch 16/30\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.2377 - acc: 0.9149 - val_loss: 0.2546 - val_acc: 0.9081\n",
            "Epoch 17/30\n",
            "48000/48000 [==============================] - 2s 32us/step - loss: 0.2353 - acc: 0.9158 - val_loss: 0.2577 - val_acc: 0.9063\n",
            "Epoch 18/30\n",
            "48000/48000 [==============================] - 2s 32us/step - loss: 0.2336 - acc: 0.9150 - val_loss: 0.2501 - val_acc: 0.9102\n",
            "Epoch 19/30\n",
            "48000/48000 [==============================] - 2s 32us/step - loss: 0.2268 - acc: 0.9185 - val_loss: 0.2536 - val_acc: 0.9106\n",
            "Epoch 20/30\n",
            "48000/48000 [==============================] - 2s 32us/step - loss: 0.2252 - acc: 0.9196 - val_loss: 0.2469 - val_acc: 0.9110\n",
            "Epoch 21/30\n",
            "48000/48000 [==============================] - 2s 32us/step - loss: 0.2191 - acc: 0.9201 - val_loss: 0.2485 - val_acc: 0.9104\n",
            "Epoch 22/30\n",
            "48000/48000 [==============================] - 2s 32us/step - loss: 0.2155 - acc: 0.9231 - val_loss: 0.2445 - val_acc: 0.9127\n",
            "Epoch 23/30\n",
            "48000/48000 [==============================] - 2s 32us/step - loss: 0.2115 - acc: 0.9241 - val_loss: 0.2470 - val_acc: 0.9127\n",
            "Epoch 24/30\n",
            "48000/48000 [==============================] - 2s 32us/step - loss: 0.2085 - acc: 0.9239 - val_loss: 0.2462 - val_acc: 0.9108\n",
            "Epoch 25/30\n",
            "48000/48000 [==============================] - 2s 32us/step - loss: 0.2058 - acc: 0.9254 - val_loss: 0.2445 - val_acc: 0.9124\n",
            "Epoch 26/30\n",
            "48000/48000 [==============================] - 2s 32us/step - loss: 0.2017 - acc: 0.9272 - val_loss: 0.2466 - val_acc: 0.9112\n",
            "Epoch 27/30\n",
            "48000/48000 [==============================] - 2s 32us/step - loss: 0.2036 - acc: 0.9256 - val_loss: 0.2433 - val_acc: 0.9151\n",
            "Epoch 28/30\n",
            "48000/48000 [==============================] - 2s 32us/step - loss: 0.1983 - acc: 0.9286 - val_loss: 0.2473 - val_acc: 0.9101\n",
            "Epoch 29/30\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.1921 - acc: 0.9299 - val_loss: 0.2398 - val_acc: 0.9153\n",
            "Epoch 30/30\n",
            "48000/48000 [==============================] - 2s 32us/step - loss: 0.1937 - acc: 0.9295 - val_loss: 0.2372 - val_acc: 0.9155\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3b4b6c2860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "metadata": {
        "id": "doteOUP9OaTx",
        "colab_type": "code",
        "outputId": "9b57f150-badf-49b1-8254-f352c91d9be2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "score = cnn_model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "print('test loss: {:.4f}'.format(score[0]))\n",
        "print(' test acc: {:.4f}'.format(score[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test loss: 0.2336\n",
            " test acc: 0.9160\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J5PBqm7jOWQX",
        "colab_type": "code",
        "outputId": "3af6fa38-b3ef-4012-d72e-5fab569bc4a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2336172239780426, 0.916]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "metadata": {
        "id": "bEBc9Jf1cykT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# our 3 models \n",
        "\n",
        "name = '1_Layer'\n",
        "cnn_model_1 = Sequential([\n",
        "    Conv2D(32, kernel_size=3, activation='relu', input_shape=im_shape, name='Conv2D-1'),\n",
        "    MaxPooling2D(pool_size=2, name='MaxPool'),\n",
        "    Dropout(0.2, name='Dropout'),\n",
        "    Flatten(name='flatten'),\n",
        "    Dense(32, activation='relu', name='Dense'),\n",
        "    Dense(10, activation='softmax', name='Output')\n",
        "], name=name)\n",
        "\n",
        "name = '2_Layer'\n",
        "cnn_model_2 = Sequential([\n",
        "    Conv2D(32, kernel_size=3, activation='relu', input_shape=im_shape, name='Conv2D-1'),\n",
        "    MaxPooling2D(pool_size=2, name='MaxPool'),\n",
        "    Dropout(0.2, name='Dropout-1'),\n",
        "    Conv2D(64, kernel_size=3, activation='relu', name='Conv2D-2'),\n",
        "    Dropout(0.25, name='Dropout-2'),\n",
        "    Flatten(name='flatten'),\n",
        "    Dense(64, activation='relu', name='Dense'),\n",
        "    Dense(10, activation='softmax', name='Output')\n",
        "], name=name)\n",
        "\n",
        "name='3_layer'\n",
        "cnn_model_3 = Sequential([\n",
        "    Conv2D(32, kernel_size=3, activation='relu', \n",
        "           input_shape=im_shape, kernel_initializer='he_normal', name='Conv2D-1'),\n",
        "    MaxPooling2D(pool_size=2, name='MaxPool'),\n",
        "    Dropout(0.25, name='Dropout-1'),\n",
        "    Conv2D(64, kernel_size=3, activation='relu', name='Conv2D-2'),\n",
        "    Dropout(0.25, name='Dropout-2'),\n",
        "    Conv2D(128, kernel_size=3, activation='relu', name='Conv2D-3'),\n",
        "    Dropout(0.4, name='Dropout-3'),\n",
        "    Flatten(name='flatten'),\n",
        "    Dense(128, activation='relu', name='Dense'),\n",
        "    Dropout(0.4, name='Dropout'),\n",
        "    Dense(10, activation='softmax', name='Output')\n",
        "], name=name)\n",
        "\n",
        "cnn_models = [cnn_model_1, cnn_model_2, cnn_model_3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c-mE4gbccymZ",
        "colab_type": "code",
        "outputId": "0f3722bb-70b1-413b-9a1e-e86a7f4ec4fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1234
        }
      },
      "cell_type": "code",
      "source": [
        "# the model summaries\n",
        "\n",
        "for model in cnn_models:\n",
        "    model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Conv2D-1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "MaxPool (MaxPooling2D)       (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "Dropout (Dropout)            (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 5408)              0         \n",
            "_________________________________________________________________\n",
            "Dense (Dense)                (None, 32)                173088    \n",
            "_________________________________________________________________\n",
            "Output (Dense)               (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 173,738\n",
            "Trainable params: 173,738\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Conv2D-1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "MaxPool (MaxPooling2D)       (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "Dropout-1 (Dropout)          (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "Conv2D-2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "Dropout-2 (Dropout)          (None, 11, 11, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 7744)              0         \n",
            "_________________________________________________________________\n",
            "Dense (Dense)                (None, 64)                495680    \n",
            "_________________________________________________________________\n",
            "Output (Dense)               (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 515,146\n",
            "Trainable params: 515,146\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Conv2D-1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "MaxPool (MaxPooling2D)       (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "Dropout-1 (Dropout)          (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "Conv2D-2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "Dropout-2 (Dropout)          (None, 11, 11, 64)        0         \n",
            "_________________________________________________________________\n",
            "Conv2D-3 (Conv2D)            (None, 9, 9, 128)         73856     \n",
            "_________________________________________________________________\n",
            "Dropout-3 (Dropout)          (None, 9, 9, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 10368)             0         \n",
            "_________________________________________________________________\n",
            "Dense (Dense)                (None, 128)               1327232   \n",
            "_________________________________________________________________\n",
            "Dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "Output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,421,194\n",
            "Trainable params: 1,421,194\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZpEECirkcyos",
        "colab_type": "code",
        "outputId": "9d242d41-2dd5-4d95-eae8-4958f1581192",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1117
        }
      },
      "cell_type": "code",
      "source": [
        "# train the models and save results to a dict\n",
        "\n",
        "history_dict = {}\n",
        "\n",
        "for model in cnn_models:\n",
        "    model.compile(\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        optimizer=Adam(),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    history = model.fit(\n",
        "        x_train, y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=10, verbose=1,\n",
        "        validation_data=(x_validate, y_validate),\n",
        "        callbacks = [TensorBoardColabCallback(tbc)]\n",
        "    )\n",
        "    \n",
        "    history_dict[model.name] = history"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.1341 - acc: 0.9515 - val_loss: 0.2484 - val_acc: 0.9187\n",
            "Epoch 2/10\n",
            "48000/48000 [==============================] - 2s 32us/step - loss: 0.1272 - acc: 0.9537 - val_loss: 0.2518 - val_acc: 0.9205\n",
            "Epoch 3/10\n",
            "48000/48000 [==============================] - 2s 32us/step - loss: 0.1281 - acc: 0.9537 - val_loss: 0.2507 - val_acc: 0.9204\n",
            "Epoch 4/10\n",
            "48000/48000 [==============================] - 2s 32us/step - loss: 0.1249 - acc: 0.9541 - val_loss: 0.2500 - val_acc: 0.9213\n",
            "Epoch 5/10\n",
            "48000/48000 [==============================] - 2s 32us/step - loss: 0.1246 - acc: 0.9544 - val_loss: 0.2536 - val_acc: 0.9186\n",
            "Epoch 6/10\n",
            "48000/48000 [==============================] - 2s 32us/step - loss: 0.1211 - acc: 0.9557 - val_loss: 0.2525 - val_acc: 0.9193\n",
            "Epoch 7/10\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.1202 - acc: 0.9565 - val_loss: 0.2572 - val_acc: 0.9198\n",
            "Epoch 8/10\n",
            "48000/48000 [==============================] - 2s 33us/step - loss: 0.1170 - acc: 0.9566 - val_loss: 0.2531 - val_acc: 0.9197\n",
            "Epoch 9/10\n",
            "48000/48000 [==============================] - 2s 32us/step - loss: 0.1184 - acc: 0.9565 - val_loss: 0.2690 - val_acc: 0.9154\n",
            "Epoch 10/10\n",
            "48000/48000 [==============================] - 2s 32us/step - loss: 0.1157 - acc: 0.9572 - val_loss: 0.2598 - val_acc: 0.9200\n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            "48000/48000 [==============================] - 3s 63us/step - loss: 0.1955 - acc: 0.9293 - val_loss: 0.2194 - val_acc: 0.9215\n",
            "Epoch 2/10\n",
            "48000/48000 [==============================] - 3s 57us/step - loss: 0.1873 - acc: 0.9313 - val_loss: 0.2198 - val_acc: 0.9186\n",
            "Epoch 3/10\n",
            "48000/48000 [==============================] - 3s 57us/step - loss: 0.1819 - acc: 0.9328 - val_loss: 0.2056 - val_acc: 0.9252\n",
            "Epoch 4/10\n",
            "48000/48000 [==============================] - 3s 58us/step - loss: 0.1729 - acc: 0.9366 - val_loss: 0.2092 - val_acc: 0.9228\n",
            "Epoch 5/10\n",
            "48000/48000 [==============================] - 3s 57us/step - loss: 0.1653 - acc: 0.9402 - val_loss: 0.2018 - val_acc: 0.9273\n",
            "Epoch 6/10\n",
            "48000/48000 [==============================] - 3s 57us/step - loss: 0.1643 - acc: 0.9395 - val_loss: 0.2029 - val_acc: 0.9259\n",
            "Epoch 7/10\n",
            "48000/48000 [==============================] - 3s 57us/step - loss: 0.1514 - acc: 0.9448 - val_loss: 0.2095 - val_acc: 0.9227\n",
            "Epoch 8/10\n",
            "48000/48000 [==============================] - 3s 57us/step - loss: 0.1475 - acc: 0.9459 - val_loss: 0.1998 - val_acc: 0.9281\n",
            "Epoch 9/10\n",
            "48000/48000 [==============================] - 3s 57us/step - loss: 0.1402 - acc: 0.9489 - val_loss: 0.2076 - val_acc: 0.9235\n",
            "Epoch 10/10\n",
            "48000/48000 [==============================] - 3s 57us/step - loss: 0.1373 - acc: 0.9492 - val_loss: 0.2027 - val_acc: 0.9280\n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            "48000/48000 [==============================] - 6s 115us/step - loss: 0.8777 - acc: 0.6764 - val_loss: 0.4855 - val_acc: 0.8162\n",
            "Epoch 2/10\n",
            "48000/48000 [==============================] - 5s 103us/step - loss: 0.5195 - acc: 0.8085 - val_loss: 0.3878 - val_acc: 0.8562\n",
            "Epoch 3/10\n",
            "48000/48000 [==============================] - 5s 103us/step - loss: 0.4359 - acc: 0.8433 - val_loss: 0.3381 - val_acc: 0.8752\n",
            "Epoch 4/10\n",
            "48000/48000 [==============================] - 5s 102us/step - loss: 0.3904 - acc: 0.8589 - val_loss: 0.2943 - val_acc: 0.8919\n",
            "Epoch 5/10\n",
            "48000/48000 [==============================] - 5s 102us/step - loss: 0.3572 - acc: 0.8717 - val_loss: 0.2855 - val_acc: 0.8948\n",
            "Epoch 6/10\n",
            "48000/48000 [==============================] - 5s 102us/step - loss: 0.3333 - acc: 0.8790 - val_loss: 0.2648 - val_acc: 0.9042\n",
            "Epoch 7/10\n",
            "48000/48000 [==============================] - 5s 102us/step - loss: 0.3153 - acc: 0.8859 - val_loss: 0.2624 - val_acc: 0.9044\n",
            "Epoch 8/10\n",
            "48000/48000 [==============================] - 5s 102us/step - loss: 0.2947 - acc: 0.8925 - val_loss: 0.2441 - val_acc: 0.9096\n",
            "Epoch 9/10\n",
            "48000/48000 [==============================] - 5s 102us/step - loss: 0.2845 - acc: 0.8971 - val_loss: 0.2437 - val_acc: 0.9080\n",
            "Epoch 10/10\n",
            "48000/48000 [==============================] - 5s 102us/step - loss: 0.2721 - acc: 0.9018 - val_loss: 0.2285 - val_acc: 0.9155\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xr5sXY53cyq4",
        "colab_type": "code",
        "outputId": "1b26e795-fed3-4988-d1a0-5079225c0b12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "cell_type": "code",
      "source": [
        "for model in cnn_models:\n",
        "  score = model.evaluate(x_test, y_test, verbose=0)\n",
        "  print('Test loss of {} is : {}'.format(model.name, score[0]))\n",
        "  print('Test accuracy of {} is : {}'.format(model.name, score[1]))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss of 1_Layer is : 0.25832980531454086\n",
            "Test accuracy of 1_Layer is : 0.9221\n",
            "Test loss of 2_Layer is : 0.2024188457608223\n",
            "Test accuracy of 2_Layer is : 0.9309\n",
            "Test loss of 3_layer is : 0.22538819749355316\n",
            "Test accuracy of 3_layer is : 0.9148\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yr9haYhLZre7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cnn_model_3.layers[-1].trainable = False\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3LLF9FC8X7DW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = cnn_model_3.output\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024, activation=\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(1024, activation=\"relu\")(x)\n",
        "predictions = Dense(16, activation=\"softmax\")(x)\n",
        "\n",
        "# creating the final model \n",
        "model_final = Model(input = model.input, output = predictions)\n",
        "\n",
        "# compile the model \n",
        "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1xkx2npCZrha",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZUlilbKXZrkJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ka_J7OvVZroJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PdbtxsHWZrsW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oAc3gmpbZru8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YdoJ-HrYZrqs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qjotUGj-Zrmp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}